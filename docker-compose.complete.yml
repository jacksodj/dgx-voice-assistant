version: '3.8'

# Simplified Qwen3-Omni Deployment with ALL Features
# - Easy DGX Spark compatible builds
# - Web UI included
# - Internet search capability
# - Persistent context/notes storage

services:
  # vLLM Model Server (pre-built, no compilation needed!)
  vllm:
    image: vllm/vllm-openai:latest
    container_name: qwen3-vllm
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_TOKEN=${HF_TOKEN}  # Optional: for gated models
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "8000:8000"
    command: >
      --model Qwen/Qwen3-Omni-30B-A3B-Instruct
      --quantization awq
      --dtype auto
      --gpu-memory-utilization 0.85
      --max-model-len 8192
      --trust-remote-code
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s

  # Enhanced Backend with Search + Storage
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: qwen3-backend
    depends_on:
      vllm:
        condition: service_healthy
    environment:
      - VLLM_API_URL=http://vllm:8000
      - BRAVE_API_KEY=${BRAVE_API_KEY}  # Get free key at brave.com/search/api
      - ENABLE_SEARCH=true
    volumes:
      - ./data:/app/data  # Persistent storage
    ports:
      - "8080:8080"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Open WebUI - Full-featured web interface
  # Has voice input, document upload, mobile support built-in!
  webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: qwen3-ui
    depends_on:
      - vllm
    ports:
      - "3000:8080"
    environment:
      - OPENAI_API_BASE_URL=http://vllm:8000/v1
      - OPENAI_API_KEY=sk-dummy  # vLLM doesn't need real key
      - WEBUI_AUTH=false  # Set to true for multi-user
      - ENABLE_RAG=true
      - ENABLE_WEB_SEARCH=true
    volumes:
      - open-webui-data:/app/backend/data
    restart: unless-stopped

  # Optional: NGINX for custom domain/SSL
  # Comment out if you don't need it
  # nginx:
  #   image: nginx:alpine
  #   container_name: qwen3-proxy
  #   depends_on:
  #     - webui
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   restart: unless-stopped

volumes:
  open-webui-data:

networks:
  default:
    name: qwen3-network
